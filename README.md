# Wikipedia Connection Finder

A modern web application that finds the shortest path between any two Wikipedia topics using intelligent cache-aware pathfinding with bidirectional BFS and real-time streaming updates.

ğŸ”— **Live Demo**: [https://wikigraph.up.railway.app](https://wikigraph.up.railway.app)

<img width="1616" height="1191" alt="image" src="https://github.com/user-attachments/assets/b53905c6-ccc6-4427-a1ad-052732e2390f" />


## âœ¨ Features

### Core Search
- **ğŸ§  Cache-Aware Pathfinding**: Intelligent system that reuses path segments from previous searches
- **âš¡ Bidirectional BFS**: 5-10x faster than traditional search with Wikipedia API optimization
- **ğŸŒ Multi-Path Discovery**: Finds up to 3 diverse paths between topics with configurable diversity
- **ğŸ“¡ Real-time Updates**: Live progress streaming using Server-Sent Events (SSE)
- **âœ… Path Validation**: Ensures all discovered paths are valid and exist on Wikipedia

### Visualization & UI
- **ğŸ•¸ï¸ Knowledge Graph**: Interactive D3.js force-directed graph showing all cached segments
  - Nodes sized by connections, colored by usage frequency (hot/cold gradient)
  - Drag nodes, zoom, pan, and hover for statistics
  - Reset layout to re-spread clustered nodes
- **ğŸ“Š Interactive Search Results**: Canvas-based visualization with clickable nodes
- **ğŸ¨ Particle Animations**: Beautiful convergence and path reveal effects
- **ğŸ¯ Modern Glass-Morphism UI**: Cyan-accented dark theme with smooth transitions

### Smart Features
- **ğŸ’¾ LRU Path Cache**: In-memory + SQLite persistence with 10,000 segment capacity
- **ğŸ” Smart Autocomplete**: Wikipedia suggestions as you type
- **ğŸ“š Collapsible Search History**: Persistent storage with filtering (collapsed by default)
- **ğŸ“ˆ Global Statistics**: Track total searches, success rate, average hops, and pages checked

## ğŸš€ Quick Start

```bash
# Clone and install
git clone https://github.com/rangulvers/Wiki_Graph.git
cd Wiki_Graph
pip install -r requirements.txt

# Run locally
python app.py

# Open browser at http://localhost:8000
```

## ğŸ› ï¸ Tech Stack

**Backend**:
- FastAPI (async web framework)
- SQLite with WAL mode (persistent storage for searches and cache)
- httpx AsyncClient (HTTP/2 connection pooling for Wikipedia API)
- Pydantic (data validation)

**Frontend**:
- Vanilla JavaScript (ES6 modules)
- D3.js v7 (force-directed graph visualization)
- Canvas API (search visualization & animations)
- Server-Sent Events (real-time updates)

**Architecture**:
- LRU cache with database persistence
- Bidirectional BFS with edge validation
- Bulk database operations for performance
- Rate limiting (SlowAPI)

**Deployment**: Railway-ready with auto-scaling

## ğŸ® Try These Connections

- **"Barack Obama" â†’ "Pizza"**
- **"Python (programming language)" â†’ "Ancient Rome"**
- **"Quantum mechanics" â†’ "Taylor Swift"**
- **"DNA" â†’ "Video game"**

## ğŸ“ˆ Performance

- **Cache Hits**: Direct hits < 100ms, composed paths < 500ms
- **BFS Search**: 2-8 seconds average (5-10x faster than traditional BFS)
- **Success Rate**: ~95% within 6 hops
- **Concurrent Users**: 50+ simultaneous searches
- **Connection Pooling**: HTTP/2 with 500 max connections, 100 keepalive
- **Database**: SQLite WAL mode with 20s timeout for concurrency
- **Animations**: 60 FPS on modern browsers

## ğŸ§  How the Cache Works

The cache-aware pathfinding system dramatically speeds up searches:

1. **Segment Caching**: Every discovered path is broken into sub-segments and cached
2. **Cache Composition**: Before running BFS, the system tries to compose a path from cached segments
3. **Validation**: All composed paths are validated to ensure edges still exist on Wikipedia
4. **LRU Eviction**: In-memory cache (10,000 segments) with database persistence
5. **Knowledge Graph**: Visualize the growing network of discovered connections

**Example**: After finding "Harry Potter â†’ Laptop", future searches can reuse segments like "Harry Potter â†’ Alfonso CuarÃ³n" or "Apple Inc. â†’ Laptop"

## ğŸŒ Deployment

Push to GitHub and connect to Railway - auto-deployment configured via `railway.json` and `Procfile`.

The app uses Railway's persistent `/data` directory for SQLite database storage, ensuring cached segments survive deployments.

## ğŸ—‚ï¸ Project Structure

```
Wiki_Graph/
â”œâ”€â”€ app.py                    # Main FastAPI application
â”œâ”€â”€ database.py              # SQLite operations (searches, cache)
â”œâ”€â”€ path_cache.py           # LRU cache with DB persistence
â”œâ”€â”€ models.py               # Pydantic models
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/style.css       # Modern glass-morphism UI
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ graphView.js    # D3.js knowledge graph
â”‚       â””â”€â”€ modules/        # ES6 modules (search, history, etc.)
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # Single-page application
â””â”€â”€ data/
    â””â”€â”€ wikipedia_searches.db  # SQLite database (persistent)
```

## ğŸ¯ API Endpoints

- `GET /` - Main application
- `POST /find-path` - Non-streaming search
- `POST /find-path-stream` - SSE streaming search
- `GET /api/searches` - Search history with filtering
- `GET /api/searches/{id}` - Individual search details
- `GET /api/stats` - Global statistics
- `GET /api/cache/stats` - Cache performance metrics
- `GET /api/cache/graph` - Knowledge graph data (nodes & edges)
- `GET /api/cache/effectiveness` - Cache utilization details

## ğŸ“ License

MIT License - Free for personal and commercial use.

---

**Built with â¤ï¸ and just for fun** | [GitHub Repository](https://github.com/rangulvers/Wiki_Graph)
